# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):
- S07-hw-dataset-01.csv
- S07-hw-dataset-02.csv
- S07-hw-dataset-03.csv

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000 строк, 9 столбцов)
- Признаки: все числовые (8 признаков + sample_id)
- Пропуски: нет
- "Подлости" датасета: признаки в сильно разных шкалах, шумовые признаки с малой вариативностью (f03, f08), требует обязательного масштабирования.

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000 строк, 4 столбца)
- Признаки: все числовые (3 признака + sample_id)
- Пропуски: нет
- "Подлости" датасета: нелинейная структура данных, наличие шумового признака z_noise с большим разбросом значений относительно основных признаков, выбросы.

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (15000 строк, 5 столбцов)
- Признаки: все числовые (4 признака + sample_id)
- Пропуски: нет
- "Подлости" датасета: кластеры разной плотности, фоновый шум, коррелированный признак f_corr, что затрудняет работу KMeans.

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: все числовые признаки масштабированы с помощью StandardScaler, пропусков не было, категориальные признаки отсутствуют.
- Поиск гиперпараметров:
  - KMeans: k от 2 до 15, выбор по максимуму silhouette score
  - DBSCAN: eps от 0.1 до 2.0 (20 значений), min_samples [2, 3, 5, 10]
  - Руководствовалась при выборе "лучшего" по максимальному значению silhouette score с учетом разумного количества кластеров (2-10)
- Метрики: silhouette_score, davies_bouldin_score, calinski_harabasz_score. Для DBSCAN метрики считались только на нешумовых точках.
- Визуализация: PCA(2D) для лучшего решения каждого датасета, графики silhouette vs k для KMeans, график для DBSCAN.

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Минимум (для каждого датасета):

- KMeans (поиск `k` 2...15, фиксировали `random_state=42`, `n_init=10`)
- Один из:
  - DBSCAN (`eps` 0.1...2.0, `min_samples` [2, 3, 5, 10])


## 4. Results

### 4.1 Dataset A

- Лучший метод и параметры: KMeans, k=2
- Метрики: silhouette=0.522, davies_bouldin=0.686, calinski_harabasz=11786.955
- DBSCAN: eps=1.70, min_samples=5, clusters=2, noise=0.0%, silhouette=0.522
- Коротко: Оба алгоритма показали одинаковое качество с выделением 2 кластеров. KMeans выбран как более простой и интерпретируемый метод при равном качестве. Разные шкалы признаков требовали масштабирования, без которого результаты были бы невалидны.
  
### 4.2 Dataset B

- Лучший метод и параметры: DBSCAN, eps=1.10, min_samples=2
- Метрики: silhouette=0.537, davies_bouldin=0.345, calinski_harabasz=15.515, (KMeans: 0.307)
- Доля шума: 0.0% (выделено только 2 точки как шум)
- Коротко: DBSCAN значительно превзошел KMeans благодаря способности работать с нелинейной структурой данных.
  
### 4.3 Dataset C

- Лучший метод и параметры: DBSCAN, eps=0.10, min_samples=10
- Метрики: silhouette=0.812, davies_bouldin=0.245, calinski_harabasz=3564.021, (KMeans: 0.316)
- Доля шума: 99.6%, кластеров: 5
- Коротко: DBSCAN показал исключительно высокий результат, правильно выделив редкие плотные области и маркировав 99.6% точек как шум. KMeans не справился с разной плотностью.


## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans "ломается" на датасетах B и C: на B из-за нелинейной структуры (silhouette 0.307 vs 0.537), на C из-за разной плотности кластеров (0.316 vs 0.812).
- DBSCAN выигрывает на датасетах с нелинейной структурой и разной плотностью, но требует тщательного подбора eps и min_samples.
- KMeans хорошо работает на датасете A со сферическими кластерами одинакового размера.
- Масштабирование было критически важно для датасета A из-за разных шкал признаков.
- Шумовые признаки не мешают DBSCAN, который может их игнорировать, но мешают KMeans.

### 5.2 Устойчивость (обязательно для одного датасета)

- Проверку устойчивости проводили для Dataset A (KMeans, k=2).
- Метод: 5 запусков с разными random_state (42, 142, 242, 342, 442), сравнение через Adjusted Rand Index.
- Результаты: ARI между первым и остальными запусками = [1.0000, 1.0000, 1.0000, 1.0000], среднее = 1.0000, стандартное отклонение = 0.0000.
- KMeans абсолютно устойчив на этом датасете, что объясняется четким разделением кластеров и их сферической формой. Алгоритм всегда сходится к одному и тому же решению.

### 5.3 Интерпретация кластеров

- Интерпретацию проводили через анализ размеров кластеров и их распределения.
- Dataset A: KMeans выделил 2 кластера размером 20% и 80%, что соответствует визуальному разделению на PCA.
- Dataset B: DBSCAN выделил 2 кластера (один 100%, второй 0% + 2 точки шума).
- Dataset C: DBSCAN выделил 5 очень маленьких кластеров (по 0.1%) и 99.6% шума, что соответствует редким плотным областям в море фонового шума.
- Вывод: Выделенные кластеры соответствуют структуре данных - либо сбалансированные группы (A), либо один доминирующий кластер с выбросами (B), либо редкие плотные ядра в шуме (C).

## 6. Conclusion

- Выбор алгоритма кластеризации критически зависит от структуры данных: KMeans для сферических кластеров, DBSCAN для сложных форм и разной плотности.
- Масштабирование обязательно для алгоритмов, основанных на расстояниях (особенно при разных шкалах признаков, как в датасете A).
- DBSCAN показывает силу на данных с шумом и нелинейной структурой, но требует аккуратного подбора параметров eps и min_samples.
- Метрика silhouette score хорошо отражает качество кластеризации и помогает сравнивать разные алгоритмы.
- Нет универсального лучшего алгоритма - на разных датасетах побеждают разные методы, что подчеркивает важность сравнительного анализа.
